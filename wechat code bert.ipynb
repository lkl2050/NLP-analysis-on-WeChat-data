{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "#import xgboost as xgb\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import layers\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "   BertTokenizerFast,\n",
    "   AutoModelForMaskedLM,\n",
    "   AutoModelForTokenClassification,\n",
    ")\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n",
    "model = AutoModelForMaskedLM.from_pretrained('ckiplab/albert-tiny-chinese') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the raw dataset\n",
    "data16 = pd.read_csv(r'/Users/cairo/Google Drive/wechat data/016.csv', sep=',', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "#data16 = pd.read_csv(r'/Users/Junhao/Google Drive/wechat data/016.csv', sep=',', error_bad_lines=False, index_col=False, dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topicdata = pd.read_csv(r'C:/Users/Junhao/Google Drive/wechat data/TopicOutcomeAll20Topic.csv', sep=',', error_bad_lines=False, index_col=False, dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this dataset is the raw data processed with cutting word package jieba(a popular word cutting tool for chinese)\n",
    "#cutword = pd.read_pickle(\"C:/Users/Junhao/Google Drive/wechat data/cut001.pkl\")\n",
    "#cutword = pd.read_pickle(\"/Users/cairo/Google Drive/wechat data/cut001.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the dataset with topic modeling output\n",
    "#topicdata = pd.read_csv(r'/Users/cairo/Google Drive/wechat data/TopicOutcomeAll20Topic.csv', sep=',', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "#topicdata = pd.read_csv(r'C:/Users/Junhao/Google Drive/wechat data/TopicOutcomeAll20Topic.csv', sep=',', error_bad_lines=False, index_col=False, dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'account',\n",
       " 'author',\n",
       " 'type',\n",
       " 'title',\n",
       " 'summary',\n",
       " 'likeCount',\n",
       " 'clicksCount',\n",
       " 'url',\n",
       " 'publicTime',\n",
       " 'orderNum',\n",
       " 'originalFlag',\n",
       " 'imageUrl',\n",
       " 'sourceUrl',\n",
       " 'videoUrl',\n",
       " 'musicUrl',\n",
       " 'audioUrl',\n",
       " 'updateTime',\n",
       " 'insertTime',\n",
       " 'wordsCut']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cutword.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'account',\n",
       " 'author',\n",
       " 'type',\n",
       " 'title',\n",
       " 'summary',\n",
       " 'likeCount',\n",
       " 'clicksCount',\n",
       " 'url',\n",
       " 'publicTime',\n",
       " 'orderNum',\n",
       " 'originalFlag',\n",
       " 'imageUrl',\n",
       " 'sourceUrl',\n",
       " 'videoUrl',\n",
       " 'musicUrl',\n",
       " 'audioUrl',\n",
       " 'updateTime',\n",
       " 'insertTime',\n",
       " 'topic0',\n",
       " 'topic1',\n",
       " 'topic2',\n",
       " 'topic3',\n",
       " 'topic4',\n",
       " 'topic5',\n",
       " 'topic6',\n",
       " 'topic7',\n",
       " 'topic8',\n",
       " 'topic9',\n",
       " 'topic10',\n",
       " 'topic11',\n",
       " 'topic12',\n",
       " 'topic13',\n",
       " 'topic14',\n",
       " 'topic15',\n",
       " 'topic16',\n",
       " 'topic17',\n",
       " 'topic18',\n",
       " 'topic19']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(topicdata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'account',\n",
       " 'author',\n",
       " 'type',\n",
       " 'title',\n",
       " 'summary',\n",
       " 'content',\n",
       " 'likeCount',\n",
       " 'clicksCount',\n",
       " 'url',\n",
       " 'publicTime',\n",
       " 'orderNum',\n",
       " 'originalFlag',\n",
       " 'imageUrl',\n",
       " 'sourceUrl',\n",
       " 'videoUrl',\n",
       " 'musicUrl',\n",
       " 'audioUrl',\n",
       " 'updateTime',\n",
       " 'insertTime']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data16.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutword1 = cutword.head(1000).wordsCut\n",
    "#cutword3 = cutword.head(1000).title  #i can also try to use only the article titles as bert input \n",
    "\n",
    "cutword2 = data16.head(500).content.dropna() #use 500 article content from rawdata as bert input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I need to cut each article to the length of 100 characters because the tokenizer can only deal with a max length of 512\n",
    "#the computation takes too long if the kept article length is long\n",
    "\n",
    "cutword3 = []\n",
    "for i in cutword2:\n",
    "    dd = i[:100]\n",
    "    cutword3.append(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今天最多人讨论的就是姚贝娜去世的新闻，满屏的悼念。但是她离开的杀手，大家是否足够了解？和梅艳芳同被乳腺癌夺取年轻的生命。今天转发一个视频希望更多女性重视这个疾病。［一分钟远离乳腺癌］VIDEO提起乳腺',\n",
       " '传递健康资讯 成就美好人生 今天不养生，明天养医生。请将健康观念传递给更多朋友。 更多精彩内容请添加小编个人微信：13861899065山有山的高度，水有水的深度，没必要攀比，每个人都有自己的长处；风',\n",
       " '↑↑↑巴西插画师 Butcher Billy 将世界各国政商圈的大爷们变成美漫里的大反派——而且看上去还挺符合他们的。他将这个系列命名为现实世界的“复仇者联盟”。Billy除了是个优秀的插画师，他还是',\n",
       " '传递健康资讯 成就美好人生 今天不养生，明天养医生。请将健康观念传递给更多朋友。 更多精彩内容请添加小编个人微信：13861899065（图为癌症患者绝望的流泪）所有人都想远离癌症、健康长寿，但你想知',\n",
       " '好贱，好贱的。哈哈！喜欢、请点底部，为一神打打气！']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutword3[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutword3 = pd.Series(cutword3)\n",
    "tokenized = cutword3.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutword3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 102)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#padding \n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 102)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#masking\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "input_ids = torch.tensor(input_ids).to(torch.int64)\n",
    "attention_mask = torch.tensor(attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([498, 102])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([498, 102])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.no_grad tells PyTorch not to construct the compute graph during this forward pass (since we won’t be running backprop here)–this just reduces memory consumption and speeds things up a little.\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe full set of hidden states for this model, stored in the object hidden_states, is a little dizzying. This object has four dimensions, in the following order:\\n\\nThe layer number (13 layers)\\nThe batch number (1 sentence)\\nThe word / token number (22 tokens in our sentence)\\nThe hidden unit / feature number (768 features)\\nWait, 13 layers? Doesn’t BERT only have 12? It’s 13 because the first element is the input embeddings, the rest is the outputs of each of BERT’s 12 layers.\\n\\nThat’s 219,648 unique values just to represent our one sentence!\\n\\nThe second dimension, the batch size, is used when submitting multiple sentences to the model at once; here, though, we just have one example sentence.\\n\\nprint (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\\nlayer_i = 0\\n\\nprint (\"Number of batches:\", len(hidden_states[layer_i]))\\nbatch_i = 0\\n\\nprint (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\\ntoken_i = 0\\n\\nprint (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use only CLS (first element of each sentence) as the feature which captures all information of the sentence\n",
    "features = last_hidden_states[0][:,0,:].numpy() \n",
    "features.shape\n",
    "'''\n",
    "The full set of hidden states for this model, stored in the object hidden_states, is a little dizzying. This object has four dimensions, in the following order:\n",
    "\n",
    "The layer number (13 layers)\n",
    "The batch number (1 sentence)\n",
    "The word / token number (22 tokens in our sentence)\n",
    "The hidden unit / feature number (768 features)\n",
    "Wait, 13 layers? Doesn’t BERT only have 12? It’s 13 because the first element is the input embeddings, the rest is the outputs of each of BERT’s 12 layers.\n",
    "\n",
    "That’s 219,648 unique values just to represent our one sentence!\n",
    "\n",
    "The second dimension, the batch size, is used when submitting multiple sentences to the model at once; here, though, we just have one example sentence.\n",
    "\n",
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 21128)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another way to get the feature is compute the average of all token vectors in each sentence\n",
    "dd = last_hidden_states[0][:,1:101,:].numpy()\n",
    "features2 = dd.mean(axis=1)\n",
    "features2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "likeCount = data16.head(500).likeCount #use likecount as dependent variable \n",
    "\n",
    "df = data16[[\"likeCount\", \"content\"]].head(1000)\n",
    "\n",
    "removeinds = pd.isnull(df).any(1).to_numpy().nonzero()[0]\n",
    "\n",
    "likeCount = [i for j, i in enumerate(likeCount) if j not in removeinds] # remove the two likecount where content is empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_output, test_output = train_test_split(features, likeCount)\n",
    "train_features2, test_features2, train_output2, test_output2 = train_test_split(features2, likeCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 78.991804\n",
      "R square: 0.687679\n",
      "RMSE: 397.117361\n",
      "R square: -6.254265\n"
     ]
    }
   ],
   "source": [
    "#training error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "reg = LinearRegression().fit(train_features, train_output)\n",
    "#reg.score(train_features, train_labels)\n",
    "preds = reg.predict(train_features)\n",
    "rmse = np.sqrt(mean_squared_error(np.array(train_output).astype(float), preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "print(\"R square: %f\" % (r2_score(np.array(train_output).astype(float), preds)))\n",
    "\n",
    "\n",
    "reg2 = LinearRegression().fit(train_features2, train_output2)\n",
    "#reg.score(train_features, train_labels)\n",
    "preds2 = reg.predict(train_features2)\n",
    "rmse2 = np.sqrt(mean_squared_error(np.array(train_output2).astype(float), preds2))\n",
    "print(\"RMSE: %f\" % (rmse2))\n",
    "print(\"R square: %f\" % (r2_score(np.array(train_output2).astype(float), preds2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 30 Jan 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.543</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:55:54</td>     <th>  Log-Likelihood:    </th> <td> -1749.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   373</td>      <th>  AIC:               </th> <td>   4218.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    13</td>      <th>  BIC:               </th> <td>   5630.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   359</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.formula.api  import ols\n",
    "import statsmodels.api as sm\n",
    "results = sm.OLS(np.array(train_output).astype(float), train_features.astype(float)).fit()\n",
    "results.summary().tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.8929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 30 Jan 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.666</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:58:33</td>     <th>  Log-Likelihood:    </th> <td> -1825.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   373</td>      <th>  AIC:               </th> <td>   4364.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    16</td>      <th>  BIC:               </th> <td>   5764.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   356</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results2 = sm.OLS(np.array(train_output2).astype(float), train_features2.astype(float)).fit()\n",
    "results2.summary().tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 242.183767\n",
      "R square: -0.650406\n"
     ]
    }
   ],
   "source": [
    "#test error\n",
    "preds = reg.predict(test_features)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(np.array(test_output).astype(float), preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "print(\"R square: %f\" % (r2_score(np.array(test_output).astype(float), preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
